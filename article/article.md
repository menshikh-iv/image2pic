# Семантичный поиск изображений на основе алгоритмов тематического моделирования

### ... и аннотированние изображений

Многие слышали об алгоритмах тематического моделирования, как об инструменте для анализа текстов. Он позволяет выявлять множества связанных "слов" -- темы -- по признаку частой совместной встречаемости в "документах", и, затем, каждый документ можно предствить в виде вектора, каждая координата которого содержит число(!): пропорцию, насколько данный документ содержит в себе данную тематику.

Однако оказывается, что "словами" могут выступать не только слова.
Как извлечь из изображения данные, которые можно считать "словами", связать их со словами на естественном языке с помощью тематического моделирования на аддитивной регуляризации и построить поиск -- читайте далее.

## The Plan

 - Цель статьи
 - Введение в тематическое моделирование
   - Очень простое введение
   - Ссылки на подробности
   - Что есть что: PLSA, LDA, HDP, ARTM, в чем разница?
   - Подробнее об ARTM
     - Главное об ARTM: концепция мультимодальности
     - Ссылки на подробности об ARTM
       - Не забыть линк на специализацию
 - Майнинг данных
   - Источник данных, фильтрация мусора
   - Предподготовка текстов
   - Предподготовка изображений
   - Оговорка о формате данных для ARTM
 - Описание модели
   - Доступные модальности
   - Листинг тематик
 - О поиске
   - Поиск по любой модальности, как это?
 - Дополнительные возможности
   - Как воспользоваться мультимодальностью модели
   - Аннотирование
 - Еще кейсы применения
   - Пользователи ВК
   - Страницы в вебе
   - Научные работы
   - Категоризация
 - Спасибо за внимание, предлагайте кейсы применения мультимодальных моделейных моделей
 - Ссылки
   - ссылка на демо(не шатайте его сильно, пожалуйста)
   - ссылка на BigARTM
   - ссылка на керас


## Цель статьи
Целью данной статьи является не полное погружение читателя в технику тематического моделирования, а демонстрация возможностей тематического моделирования. Тема очень большая, по ней написано очень много хороших материалов, поэтому своей задачей я вижу замотивировать читателя углубиться в эту тематику.

Поэтому в статье будут опущены некоторые важные детали(на важные детали будут даны ссылки): теоретическая часть будет посвящена скорее необходимым для понимания концепциям, чем истинной механике работы тематического моделирования.

## Введение в тематическое моделирование
### Очень простое введение
#### Немного терминологии
Слова(или "термы", "токены") -- мельчайшая единица, чаще всего являются нормализованными словами. Можно мнить их как столбики в таблице, задающей дискретное распределение.
Сумка слов(bag of words) -- неупорядоченный словарь, ключами являются токены, значениями количество их употреблений.
Документ -- сущность, которая объединаяет слова. Причем мы пользуемся моделью "сумки слов", для которой не важен порядок слов, важно только количество включений каждого слова в документ. Чаще всего документом является просто текст, но далее мы покажем, что документом может быть более сложная сущность.
Корпус -- набор документов. Иногда предполагается, что этот набор документов уже подготовлен к машинной обработке.
Тематическое моделирование(далее просто ТМ) -- набор техник, без дополнительной разметки по корпусу выявляющий связанные одной тематикой термы.

### Как это примерно работает

Сначала вы устанавливаете предполагаемое количество тем в вашем корпусе. Обычно, это число от 30 до 300(в моей практике), его можно установить "на глаз".
По корпусу вы запускаете алгоритм, который строит матрицу фи(phi, todo воткнуть греческую фи). Еще он строит матрицу тета, но сегодня она нам неинтересна.
Матрица фи имеет размерность NxM, где N -- количество уникальных слов в словаре, а M -- количество тем.
В ячейке phi[i,j] расположена вероятность принадлежности итого слова йотой теме(туду, проверить).

Теперь очень понятно, как дальше применять эту матрицу фи: мы строим вектор-сумку-слов(размерности N) для данного документа, умножаем его на матрицу фи(размерности NxM), получаем тематический вектор размерности(M), который описывает тематический состав данного документа.

Всё.
### Ссылки на подробности
TODO Линк на самую понятную статью Воронцова по этой теме

### Что есть что: PLSA, LDA, HDP, ARTM, в чем разница?
PLSA, LDA и HDP -- это достаточно старые и устоявшиеся алгоритмы тематического моделирования. Можно сказать, что каждый следующий это надстройка над предыдущим. Все они используют байесовский подход и понятия сопряженных распределений. Для их работы делаются некоторые предположения, которые не всегда выполняются и, поскольку в процессе конструирования этих алгоритмов берётся сложный  интеграл(благодаря сопряженным распределениям и жестким предположениям это делается относительно безболезненно), эти алгоритмы сложно адаптировать ко многим реальным условиям использования: короткие тексты, странные распределения термов, мультимодальность.

ARTM в свою очередь даёт инструмент для конструирования моделей под любую зачачу. В основе лежит идея регуляризации через KL-дивергенцию(мера похожести вероятностных распределений). Фреймворк включает в себя различные регуляризаторы, которые можно добавлять в модель, чтобы добавлять модели желаемых свойств. Платим мы за это большим количеством коэфициентов, теоретического обоснования для подбора которых пока нет.

### Подробнее об ARTM
TODO где подробнее прочитать про ARTM

#### Главное об ARTM: концепция мультимодальности
Давайте внимательнее взглянем на понятие модальности, что это?

Давайте попробуем понять это на примере модели языка.
Итак мысленный эксперимент. Представим себе автора, который пишет какой-то текст. Предположим, это проходная статья на хабр о биоисследованиях в космосе. То есть текст будет состоять на 20% из инженерной темы, на 30% из биологичеческой и на 50% из общей лексики. Сделаем оговорку, что наш автор -- не очень хороший автор: вместо грамотного погружения в тему он пишет статьи иначе. Он изготовил трёхгранный "кубик" с площадью сторон 0.2 см^2, 0.3 

Внимание на схему ниже.

![big_scheme](./big_schema.png)
        - Ссылки на подробности об ARTM
          - Не забыть линк на специализацию
    - Майнинг данных
      - Источник данных, фильтрация мусора
      - Предподготовка текстов
      - Предподготовка изображений
      - Оговорка о формате данных для ARTM
    - Описание модели
      - Доступные модальности
      - Листинг тематик
    - О поиске
      - Поиск по любой модальности, как это?
    - Дополнительные возможности
      - Как воспользоваться мультимодальностью модели
      - Аннотирование
    - Еще кейсы применения
      - Пользователи ВК
      - Страницы в вебе
      - Научные работы
      - Категоризация
    - Спасибо за внимание, предлагайте кейсы применения мультимодальных моделейных моделей
    - Ссылки
      - ссылка на демо(не шатайте его сильно, пожалуйста)
      - ссылка на BigARTM
      - ссылка на керас
