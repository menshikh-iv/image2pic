{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('bigartm-0.8.2-py2.7.egg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loglevel = int(os.environ.get('LOGLEVEL', '00'))\n",
    "logfile = os.environ.get('LOGFILE', 'artm.log')\n",
    "model_file = os.environ.get('MODELNAME', '../models/big_model.artm.mtx')\n",
    "insception_classes_file = os.environ.get('INSCLASSES', '../resourses/insception-classes.tsv')\n",
    "zmq_port = int(os.environ.get('ZMQPORT', '1349'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=loglevel)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s', datefmt='%H:%M:%S')\n",
    "\n",
    "logger = logging.getLogger('ZMQ_ARTM')\n",
    "fh = logging.FileHandler(logfile)\n",
    "fh.setLevel(loglevel)\n",
    "fh.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)\n",
    "\n",
    "logger.info('Logging started.')\n",
    "logger.info('Initialisation started...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.info('Launch parameters: ')\n",
    "for k,v in [('model_file', model_file), \n",
    "            ('insception_classes_file', insception_classes_file),\n",
    "            ('zmq_port', zmq_port)]:\n",
    "    logger.info('  ...\\t\"%s\" is equal to \"%s\"', k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import artm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import zmq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import sample_from, get_text_processor, prepare_for_artm, apply_box_cox\n",
    "from collections import Counter\n",
    "\n",
    "logger.info('Building text processor from %s', get_text_processor)\n",
    "text_processor = get_text_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modalities_set = set(['classes', 'tag', 'text'])\n",
    "logger.info('Possible modalities for inpus are: %s', modalities_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.info('Reading class names for insception from %s', insception_classes_file)\n",
    "with open(insception_classes_file) as income:\n",
    "    class_mapping = dict(map(lambda l: map(str.strip, l.split('\\t')), income))\n",
    "class_names = [class_mapping[str(_)] for _ in range(0, 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparsed_topics = 39\n",
    "smoothed_topics = 5\n",
    "\n",
    "logger.info('Building ARTM-object...')\n",
    "\n",
    "topics = ['good_%i'%_ for _ in range(sparsed_topics)] + ['mess_%s'%_ for _ in range(smoothed_topics)]\n",
    "\n",
    "tm = artm.ARTM(num_topics=44, num_processors=2)\n",
    "\n",
    "logger.info('Loading ARTM-model from %s', model_file)\n",
    "tm.load(model_file)\n",
    "tm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='text_sparser', tau=-0.7, class_ids=['text']))\n",
    "tm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='classes_sparser', tau=-0.3, class_ids=['classes']))\n",
    "tm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='tags_smoother', tau=1, class_ids=['tag']))\n",
    "tm.regularizers.add(artm.SmoothSparseThetaRegularizer(name='topic_sparser', tau=-2, topic_names=topics[:sparsed_topics]))\n",
    "tm.regularizers.add(artm.SmoothSparseThetaRegularizer(name='topic_smoother', tau=2.5, topic_names=topics[smoothed_topics:]))\n",
    "\n",
    "logger.info('ARTM object is ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.info('Gathering available words for futher query checking...')\n",
    "available_words = set(tm.get_phi(class_ids=['text']).index)\n",
    "logger.info('There available %d words', len(available_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_desc(tm, score_name, n_objcts, renamer={}):\n",
    "    topic_desc = {}\n",
    "\n",
    "    collection = tm.get_phi(class_ids=[score_name]).T.copy()\n",
    "    \n",
    "    if score_name in renamer:\n",
    "        collection.columns = [renamer[score_name][c] for c in collection.columns]\n",
    "    \n",
    "    non_active_topics = collection.index[collection.sum(axis=1) < 0.5]\n",
    "    logger.warn('Next topics are not active for \"%s\" modality: %s', score_name, list(non_active_topics))\n",
    "    collection = collection[~collection.index.isin(non_active_topics)]\n",
    "    \n",
    "    collection.iloc[:,:] = (collection.values/collection.sum(axis=1).values[:, np.newaxis])\n",
    "\n",
    "    for topic in collection.index:\n",
    "        topic_sample = collection.loc[topic].sort_values(ascending=False)[:n_objcts]\n",
    "\n",
    "        topic_desc[topic] = ', '.join(['%s:%3.3f'%(word, weight) for word, weight in topic_sample.iteritems()])\n",
    "    return topic_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.info('Building description for %s modalities', modalities_set)\n",
    "\n",
    "desc_pack = {}\n",
    "\n",
    "numbers = {'text': 20, 'classes': 20, 'tag': 4}\n",
    "\n",
    "for modality in modalities_set:\n",
    "    desc_pack[modality] = get_desc(tm, modality, numbers[modality], {'classes': class_mapping})\n",
    "\n",
    "logger.info('Building description for regularizers',)\n",
    "\n",
    "reg_info = []\n",
    "for rname, obj in tm.regularizers.data.items():\n",
    "    reg_info.append({'reg_type': type(obj).__name__, 'reg_name':rname, 'tau_coef':obj.tau})\n",
    "\n",
    "model_description = {'regularizers': reg_info, 'modalities_desc': desc_pack, 'topics': tm.topic_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.info('Gathering topic description with text modality...')\n",
    "text_about_topics = get_desc(tm, 'text', 8, {})\n",
    "logger.info('Gathering topic description with classes modality...')\n",
    "classes_about_topics = get_desc(tm, 'classes', 5, {'classes': class_mapping})\n",
    "\n",
    "logger.info('Pregenerating descriptions of topics')\n",
    "topics_desc = ['%s: %30s\\n%50s'%(topic_name, \n",
    "                            text_about_topics.get(topic_name, ''), \n",
    "                            classes_about_topics.get(topic_name, '')) for topic_name in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for topic, row in pd.DataFrame(model_description['modalities_desc']).iterrows():\n",
    "    logger.debug('%s:', topic)\n",
    "    for c in row.index:\n",
    "        logger.debug('\\t%s: %s', c, row[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.debug(model_description['regularizers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top(row, treshold=0.95, number=5):\n",
    "    sorted_row = row.sort_values(ascending=False)\n",
    "    \n",
    "    res = []\n",
    "    prob_mass = 0\n",
    "    for k, val in sorted_row.iteritems():\n",
    "        prob_mass+=val\n",
    "        res.append((k, val))\n",
    "        if prob_mass>treshold:\n",
    "            break\n",
    "        if len(res)==number:\n",
    "            res.append(('other', (1. - prob_mass)))\n",
    "            break\n",
    "    \n",
    "    return [(l[0], float(l[-1])) for l in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_available_data(df_in):\n",
    "    if 'text' in df_in:\n",
    "        df_in.text = df_in.text.apply(text_processor).apply(Counter)\n",
    "\n",
    "    if 'classes' in df_in:\n",
    "        df_in.classes = df_in.classes.apply(np.array).apply(sample_from)\n",
    "    \n",
    "    return df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoInfoAvailable(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_with_enough_data(df_in, available_words=available_words):\n",
    "    logger.debug('Cheking if there available info for TM:')\n",
    "    logger.debug('\\t ... columns of DF: %s'% df_in.columns)\n",
    "    \n",
    "    if len(set(df_in.columns) & modalities_set) == 0:\n",
    "        return df_in.drop(df_in.index, axis=0)\n",
    "    \n",
    "    logger.debug('\\t ... there is exists some modality')\n",
    "    \n",
    "    if len(set(df_in.columns) & modalities_set) == 1 and 'text' in df_in.columns:\n",
    "        logger.debug('\\t ... the only modality is \"text\", checkng if there are some known words...')\n",
    "        logger.debug('\\t ... available records are: %s', list(df_in.index))\n",
    "        good_idxs = df_in.text.apply(lambda wrds: len(set(wrds.keys()) & available_words) > 0)\n",
    "        logger.debug('\\t ... records with enouth text data are: %s', list(df_in.loc[good_idxs].index))\n",
    "        return df_in.loc[good_idxs]\n",
    "    \n",
    "    logger.debug('\\t ... there is exists image modality')\n",
    "    \n",
    "    return df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_insception_classes(tm, batch):\n",
    "    return list(tm.transform(batch, predict_class_id='classes').T.sort_index().T\\\n",
    "                                .apply(lambda r: apply_box_cox(r.values), axis=0)\\\n",
    "                                .apply(lambda p: get_top(pd.Series(p.values, index=p.index.map(class_mapping.get)), 0.5, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text_description(tm, batch):\n",
    "    return list(tm.transform(batch, predict_class_id='text').T.sort_index().T\\\n",
    "                            .apply(lambda r: get_top(r, 0.2, 20), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_tags(tm, batch):\n",
    "    return list(tm.transform(batch, predict_class_id='tag').T.sort_index().T\\\n",
    "                            .apply(lambda r: get_top(r, 0.2, 5), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_marker = 'predicted_'\n",
    "\n",
    "views_keys = dict(text='tokens_from_raw_text', classes='classes_multinomial_params')\n",
    "\n",
    "def transform_operation(data_in, temp_name='temp', modalities_to_generate=modalities_set):\n",
    "    df_in = pd.DataFrame(data_in)\n",
    "\n",
    "    prepare_available_data(df_in)\n",
    "    \n",
    "    df_in = filter_with_enough_data(df_in)\n",
    "    \n",
    "    if df_in.shape[0] == 0:\n",
    "        raise NoInfoAvailable()\n",
    "    else:\n",
    "        logger.debug('There enough info for computing')\n",
    "    \n",
    "    batch = prepare_for_artm(df_in, temp_name)\n",
    "\n",
    "    if 'classes' in modalities_to_generate: \n",
    "        df_in[predicted_marker + 'classes'] = generate_insception_classes(tm, batch)\n",
    " \n",
    "    if 'text' in modalities_to_generate: \n",
    "        df_in[predicted_marker + 'text'] = generate_text_description(tm, batch)\n",
    "\n",
    "    if 'tag' in modalities_to_generate: \n",
    "        df_in[predicted_marker + 'tag'] = generate_tags(tm, batch)\n",
    "   \n",
    "\n",
    "    df_in['topics'] = map(lambda (k, row): map(float, row), tm.transform(batch).T.sort_index().iterrows())\n",
    "    \n",
    "    outcome = []\n",
    "    for u, data in df_in.iterrows():\n",
    "        result = data.to_dict()\n",
    "        ans = dict()\n",
    "        \n",
    "        ans['id'] = u\n",
    "        ans['topics'] = result['topics']\n",
    "        ans['topics_desc'] = topics_desc\n",
    "        ans['modalities'] = dict()\n",
    "        ans['view'] = dict()\n",
    "        \n",
    "        for predicted_field in [_ for _ in result.keys() if _.startswith(predicted_marker)]:\n",
    "            ans['modalities'][predicted_field[len(predicted_marker):]] = result[predicted_field]\n",
    "        \n",
    "        for passed_field in set(views_keys.keys()) & set(result.keys()):\n",
    "            ans['view'][views_keys[passed_field]] = result[passed_field]\n",
    "            if passed_field == 'classes':\n",
    "                ans['view'][views_keys[passed_field]] = {class_mapping[str(k)]:v for k,v in ans['view'][views_keys[passed_field]].items()}\n",
    "            \n",
    "        outcome.append(u'%s\\n'% json.dumps(ans))\n",
    "    \n",
    "    return '[%s]'% ', \\n'.join(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.info('Starting ZMQ context')\n",
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.REP)\n",
    "\n",
    "bind_addr =\"tcp://*:%i\"%zmq_port\n",
    "logger.info('Binding %s zmq socket on adress %s', 'zmq.REP', bind_addr)\n",
    "socket.bind(bind_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.info('Ready to work')\n",
    "logger.info('Starting infinite handler loop...')\n",
    "try:\n",
    "    while True:\n",
    "        logger.debug('ready to recieve')\n",
    "        income = socket.recv_json()\n",
    "        logger.debug('income is %s', income)\n",
    "        command = income.pop('command')\n",
    "        logger.debug('The command is %s', command)\n",
    "        if command == 'transform':\n",
    "            income = income.pop('data')\n",
    "            \n",
    "            resp_status = None\n",
    "            \n",
    "            try:\n",
    "                res = transform_operation(income)\n",
    "                resp_status='ok'\n",
    "            except NoInfoAvailable as e:\n",
    "                resp_status='little_of_data'\n",
    "                res = '\"\"'\n",
    "            except Exception as e:\n",
    "                resp_status='unknown_error'\n",
    "                res = '\"%s\"'%e.message\n",
    "                logger.exception(e)\n",
    "                \n",
    "            res =  '{\"status\": \"%s\", \"response\": %s}'%(resp_status, res)\n",
    "        elif command == 'info':\n",
    "            res = json.dumps(model_description)\n",
    "        else:\n",
    "            logger.warn('Skipping unknown command: \"%s\"', command)\n",
    "            continue\n",
    "        logger.debug('result is %s', res)\n",
    "        socket.send_string(res.decode('utf8'))\n",
    "        logger.debug('answer was sent')\n",
    "except Exception as e:\n",
    "    logger.exception(e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "0313c78133ce43ad8cb17030d62c694f": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "10b3ff4bf115462e8bea297cdee5930b": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "3b763dfa7c434257b7faea8dba274221": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "4023f428018845e8a1e4bf96fa50664a": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "5e61e363e3d94a69a2cf86853daa612e": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "fc4ddcca48294f1db26a92fc0479353c": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
